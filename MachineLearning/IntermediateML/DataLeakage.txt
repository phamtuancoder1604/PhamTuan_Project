1. Giới thiệu về Data Leakage
Data leakage (rò rỉ dữ liệu) xảy ra khi dữ liệu huấn luyện chứa thông tin về biến mục tiêu mà dữ liệu thực tế khi dự đoán không có. Điều này khiến mô hình có độ chính xác cao trên tập huấn luyện và kiểm định nhưng hoạt động kém trong thực tế.

Có hai loại rò rỉ dữ liệu chính:

Target Leakage (Rò rỉ mục tiêu)
Train-Test Contamination (Ô nhiễm huấn luyện-kiểm định)
2. Target Leakage
Xảy ra khi một đặc trưng trong dữ liệu huấn luyện chỉ có sau khi biến mục tiêu được xác định. Ví dụ:

got_pneumonia	age	weight	took_antibiotic_medicine
False	65	100	False
False	72	130	False
True	58	100	True
Ở đây, việc một người có uống kháng sinh hay không là thông tin chỉ có sau khi họ mắc viêm phổi. Nếu sử dụng đặc trưng này để huấn luyện mô hình, mô hình sẽ dự đoán sai khi áp dụng vào thực tế vì khi dự đoán thì chưa có thông tin này.

Cách phòng tránh: Loại bỏ bất kỳ biến nào được tạo ra sau khi biến mục tiêu xảy ra.

3. Train-Test Contamination
Xảy ra khi dữ liệu huấn luyện và kiểm định không được phân tách đúng, khiến mô hình học được thông tin từ tập kiểm định. Ví dụ:

Thực hiện xử lý dữ liệu (như điền giá trị thiếu) trước khi chia dữ liệu thành tập huấn luyện và kiểm định.
Khi làm feature engineering mà vô tình sử dụng thông tin từ tập kiểm định.
Cách phòng tránh:

Chia dữ liệu trước khi thực hiện xử lý trước.
Sử dụng pipelines trong scikit-learn để đảm bảo không làm rò rỉ dữ liệu.
4. Ví dụ về phát hiện Target Leakage
Bộ dữ liệu về ứng dụng thẻ tín dụng:

card: 1 nếu được duyệt, 0 nếu bị từ chối.
expenditure: Chi tiêu trung bình hàng tháng bằng thẻ tín dụng.
Sau khi kiểm tra, phát hiện rằng tất cả những người không được cấp thẻ đều có chi tiêu = 0, trong khi chỉ có 2% người được cấp thẻ có chi tiêu = 0. Điều này cho thấy expenditure có thể là thông tin bị rò rỉ (liên quan trực tiếp đến kết quả phê duyệt thẻ).

Cách xử lý: Loại bỏ các biến tiềm ẩn gây rò rỉ (expenditure, share, active, majorcards).

Sau khi loại bỏ các biến này, độ chính xác của mô hình giảm từ 98% xuống 83%, nhưng mô hình này sẽ hoạt động tốt hơn trên dữ liệu thực tế.

5. Kết luận
Data leakage có thể gây ra sai sót nghiêm trọng, đặc biệt trong các ứng dụng thương mại. Để tránh rò rỉ dữ liệu:

Tách biệt dữ liệu huấn luyện và kiểm định đúng cách.
Sử dụng pipelines để đảm bảo quy trình xử lý dữ liệu nhất quán.
Kiểm tra cẩn thận các đặc trưng có nguy cơ gây rò rỉ dữ liệu.






Nói đơn giản, data leakage (rò rỉ dữ liệu) xảy ra khi mô hình học được thông tin mà nó không thể có trong thực tế khi đưa vào sử dụng. Điều này khiến mô hình hoạt động rất tốt trên dữ liệu huấn luyện và kiểm định, nhưng khi áp dụng vào thực tế lại cho kết quả kém.

Ví dụ để dễ hiểu:

Giả sử bạn muốn dự đoán xem một người có bị viêm phổi không.
Bạn có một tập dữ liệu chứa các đặc trưng như:

Tuổi
Cân nặng
Giới tính
Người đó có uống thuốc kháng sinh không?
Giả sử bạn dùng dữ liệu này để huấn luyện mô hình, và nó cho kết quả rất chính xác. Nhưng vấn đề là:

Người chỉ uống kháng sinh sau khi họ bị viêm phổi.
Khi bạn dự đoán xem một người có bị viêm phổi hay không, bạn không thể biết trước họ có uống kháng sinh hay không (vì họ chưa mắc bệnh mà!).
🔴 Lỗi ở đây là mô hình đã học từ một đặc trưng mà chỉ có sau khi sự kiện xảy ra → Mô hình sẽ không hoạt động tốt trong thực tế.

➡ Cách phòng tránh: Không sử dụng các biến được tạo ra sau khi kết quả đã có, chỉ dùng thông tin có sẵn tại thời điểm cần dự đoán.









Câu này có nghĩa là: Nếu dữ liệu huấn luyện và dữ liệu kiểm định (validation/test set) không được phân tách đúng, mô hình có thể vô tình nhìn thấy thông tin từ tập kiểm định trong quá trình học. Điều này làm cho mô hình có vẻ hoạt động rất tốt khi kiểm tra, nhưng khi áp dụng vào dữ liệu thực tế lại kém hiệu quả.

Ví dụ cụ thể về Train-Test Contamination
Sai lầm phổ biến:
Giả sử bạn có một tập dữ liệu và bạn muốn:

Xử lý dữ liệu (ví dụ: điền giá trị thiếu, chuẩn hóa, chọn đặc trưng).
Chia dữ liệu thành tập huấn luyện (train set) và tập kiểm định (test set).
Huấn luyện mô hình trên tập huấn luyện và đánh giá trên tập kiểm định.
❌ Lỗi train-test contamination xảy ra khi bạn thực hiện bước 1 trước khi chia dữ liệu.

Ví dụ: Bạn sử dụng toàn bộ dữ liệu để tính trung bình các giá trị thiếu và sau đó chia thành tập huấn luyện và kiểm định. Khi đó:

Mô hình đã học được thông tin từ tập kiểm định ngay từ đầu, vì giá trị trung bình được tính dựa trên cả hai tập.
Điều này có thể làm cho mô hình có vẻ hoạt động tốt trong quá trình kiểm định, nhưng khi áp dụng vào dữ liệu thực tế, kết quả có thể không tốt như mong đợi.
✔ Cách phòng tránh:

Luôn chia dữ liệu trước khi thực hiện bất kỳ xử lý nào.
Khi sử dụng scikit-learn, hãy dùng pipelines để đảm bảo rằng tất cả các bước xử lý chỉ áp dụng trên tập huấn luyện.
Nếu dùng cross-validation, hãy đảm bảo rằng mọi thao tác tiền xử lý đều được thực hiện trong từng lần huấn luyện, tránh lấy thông tin từ dữ liệu kiểm định.
Tóm lại:
🚨 Train-test contamination xảy ra khi dữ liệu kiểm định ảnh hưởng đến quá trình học của mô hình, làm cho mô hình có vẻ chính xác trong kiểm định nhưng không tổng quát được cho dữ liệu mới.